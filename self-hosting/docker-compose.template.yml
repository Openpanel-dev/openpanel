version: "3"

services:
  op-proxy:
    image: caddy:2-alpine
    restart: always
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - op-proxy-data:/data
      - op-proxy-config:/config
      - ./caddy/Caddyfile:/etc/caddy/Caddyfile
    depends_on:
      op-dashboard:
        condition: service_healthy
      op-api:
        condition: service_healthy
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  op-db:
    image: postgres:14-alpine
    restart: always
    volumes:
      - op-db-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # Uncomment to expose ports
    # ports:
    #   - 5432:5432

  op-kv:
    image: redis:7.2.5-alpine
    restart: always
    volumes:
      - op-kv-data:/data
    command: ["redis-server", "--maxmemory-policy", "noeviction"]
    healthcheck:
      test: ["CMD-SHELL", "redis-cli ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # Uncomment to expose ports
    # ports:
    #   - 6379:6379

  op-ch:
    image: clickhouse/clickhouse-server:25.10.2.65
    restart: always
    volumes:
      - op-ch-data:/var/lib/clickhouse
      - op-ch-logs:/var/log/clickhouse-server
      - ./clickhouse/clickhouse-config.xml:/etc/clickhouse-server/config.d/op-config.xml:ro
      - ./clickhouse/clickhouse-user-config.xml:/etc/clickhouse-server/users.d/op-user-config.xml:ro
      - ./clickhouse/init-db.sh:/docker-entrypoint-initdb.d/init-db.sh:ro
    environment:
      - CLICKHOUSE_SKIP_USER_SETUP=1
    healthcheck:
      test: ["CMD-SHELL", 'clickhouse-client --query "SELECT 1"']
      interval: 10s
      timeout: 5s
      retries: 5
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  op-api:
    image: lindesvard/openpanel-api:2
    restart: always
    command: >
      sh -c "
        echo 'Running migrations...'
        CI=true pnpm -r run migrate:deploy

        pnpm start
      "
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/healthcheck || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      op-db:
        condition: service_healthy
      op-ch:
        condition: service_healthy
      op-kv:
        condition: service_healthy
    env_file:
      - .env
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  op-dashboard:
    image: lindesvard/openpanel-dashboard:2
    restart: always
    depends_on:
      op-api:
        condition: service_healthy
    env_file:
      - .env
    healthcheck:
      test:
        ["CMD-SHELL", "curl -f http://localhost:3000/api/healthcheck || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "3"

  op-worker:
    image: lindesvard/openpanel-worker:2
    restart: always
    depends_on:
      op-api:
        condition: service_healthy
    env_file:
      - .env
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/healthcheck || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      mode: replicated
      replicas: $OP_WORKER_REPLICAS
    logging:
      driver: "json-file"
      options:
        max-size: "30m"
        max-file: "3"

volumes:
  op-db-data:
    driver: local
  op-kv-data:
    driver: local
  op-ch-data:
    driver: local
  op-ch-logs:
    driver: local
  op-proxy-data:
    driver: local
  op-proxy-config:
    driver: local
